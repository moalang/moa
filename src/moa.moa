class Token {
  code   str
  file   str
  offset int
  lineno int
  column int
}

class Node {
  token Token
}

def generate nodes {
  def genjs node {
  }
  return nodes.map(genjs).join("\n")
}

def tokenize program file {
  let reg r/(r\/(?:[^\/\\]|\\.)*?\/[A-Za-z]*|[0-9]+|(?:\.\.\.)?[A-Za-z0-9_]+|[\.()[\]{}]|"(?:[^"\\]|\\.)*"|`(?:[^`\\]|\\.)*`|[+\-*\/%<>!=^|&]+|#[^\n]*| +|\n+)/g
  var offset 0
  var lineno 1
  var column 1
  var tokens []
  each code program.match(reg) {
    if code.starts("\n") {
      lineno += code.count("\n")
      column = 1
    } else if code.starts(" ") && column == 1 {
      column += code.size
    } else {
      tokens.push Token(code file offset lineno column)
    }
    offset += code.size
  }
  return tokens
}

test t {
}

def parse tokens {
  return []
}

def infer nodes {
  return nodes
}

test t {
}
